{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = './daic/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_txt_to_csv(base_url, feature):\n",
    "    pids = [f for f in os.listdir(base_url) if len(f) == 3]\n",
    "    for pid in tqdm(pids, desc='Converting txt to csv', ascii=\"░▒█\"):\n",
    "        txt_file_path = f'{base_url}{pid}/{pid}_CLNF_{feature}.txt'\n",
    "        \n",
    "        if os.path.isfile(txt_file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(txt_file_path, delimiter=',', low_memory=False)\n",
    "                df.iloc[:, 4:] = df.iloc[:, 4:].astype(np.float32)\n",
    "                \n",
    "                csv_file_path = f'{base_url}{pid}/{pid}_CLNF_{feature}.csv'\n",
    "                \n",
    "                df.to_csv(csv_file_path, index=False)\n",
    "                \n",
    "                os.remove(txt_file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {txt_file_path}. Error: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"File {txt_file_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unsucc(input_dir, feature):\n",
    "    pids = [f for f in os.listdir(input_dir) if len(f) == 3]\n",
    "\n",
    "    for pid in tqdm(pids, desc=\"Remove unsuccessful frames\", ascii=\"░▒█\"):\n",
    "        file_path = f'{input_dir}{pid}/{pid}_CLNF_{feature}.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df[' success'] == 1]\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Remove unsuccessful frames:   0%|░░░░░░░░░░| 0/189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Remove unsuccessful frames: 100%|██████████| 189/189 [20:42<00:00,  6.57s/it]\n",
      "Remove unsuccessful frames: 100%|██████████| 189/189 [01:49<00:00,  1.72it/s]\n",
      "Remove unsuccessful frames: 100%|██████████| 189/189 [02:03<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "remove_unsucc(base_url, 'features')\n",
    "remove_unsucc(base_url, 'AUs')\n",
    "remove_unsucc(base_url, 'gaze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_reference(input_dir):\n",
    "    all_nosetip_x = []\n",
    "    all_nosetip_y = []\n",
    "\n",
    "    pids = [f for f in os.listdir(input_dir) if len(f) == 3]\n",
    "\n",
    "    # Iterate over each file to collect nosetip data\n",
    "    for folder_name in tqdm(pids, desc=\"Calculating global nosetip\", ascii=\"░▒█\"):\n",
    "        folder_path = input_dir + folder_name + '/'\n",
    "        df = pd.read_csv(f'{folder_path}{folder_name}_CLNF_features.csv')\n",
    "\n",
    "        all_nosetip_x.extend(df[' x33'].values)\n",
    "        all_nosetip_y.extend(df[' y33'].values)\n",
    "\n",
    "    # Calculate the global mean or median of the nosetip coordinates\n",
    "    global_nosetip_x = np.mean(all_nosetip_x)\n",
    "    global_nosetip_y = np.mean(all_nosetip_y)\n",
    "\n",
    "    return global_nosetip_x, global_nosetip_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating global nosetip: 100%|██████████| 189/189 [03:03<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "glob_nt_x, glob_nt_y = calculate_global_reference(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_min_max(base_url, feature):\n",
    "    global_min = np.inf\n",
    "    global_max = -np.inf\n",
    "\n",
    "    pids = [f for f in os.listdir(base_url) if len(f) == 3]\n",
    "\n",
    "    for folder_name in tqdm(pids, desc=\"Calculating global min/max\", ascii=\"░▒█\"):\n",
    "        file_path = f'{base_url}{folder_name}/{folder_name}_CLNF_{feature}.csv'\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            df = pd.read_csv(file_path, delimiter=',')\n",
    "            global_x_min = min(global_min, df.iloc[:, 4:72].min().min())\n",
    "            global_x_max = max(global_max, df.iloc[:, 4:72].max().max())\n",
    "            global_y_min = min(global_min, df.iloc[:, 72:].min().min())\n",
    "            global_y_max = max(global_max, df.iloc[:, 72:].max().max())\n",
    "    \n",
    "    return global_x_min, global_x_max, global_y_min, global_y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating global min/max: 100%|██████████| 189/189 [03:06<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "glob_x_min, glob_x_max, glob_y_min, glob_y_max = calculate_global_min_max(base_url, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017.3300170898438"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob_x_min\n",
    "# glob_x_max\n",
    "# glob_y_min\n",
    "# glob_y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_landmarks(df, glob_nt_x, glob_nt_y, glob_x_min, glob_x_max, glob_y_min, glob_y_max):\n",
    "\n",
    "    current_nt_x = df[' x33'].values\n",
    "    current_nt_y = df[' y33'].values\n",
    "\n",
    "    df.iloc[:, 4:72] = df.iloc[:, 4:72].subtract(current_nt_x, axis=0)\n",
    "    df.iloc[:, 72:] = df.iloc[:, 72:].subtract(current_nt_y, axis=0)\n",
    "\n",
    "    df.iloc[:, 4:72] = df.iloc[:, 4:72].add(glob_nt_x, axis=0)\n",
    "    df.iloc[:, 72:] = df.iloc[:, 72:].add(glob_nt_y, axis=0)\n",
    "\n",
    "    df.iloc[:, 4:72] = (df.iloc[:, 4:72] - glob_x_min) / (glob_x_max - glob_x_min)\n",
    "    df.iloc[:, 72:] = (df.iloc[:, 72:] - glob_y_min) / (glob_y_max - glob_y_min)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pid = '367'\n",
    "# test_df = pd.read_csv(f'./daic/data/{pid}/{pid}_CLNF_features.csv')\n",
    "# normalize_landmarks(test_df, glob_nt_x, glob_nt_y, glob_x_min, glob_x_max, glob_y_min, glob_y_max)[' x33']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalising landmarks feature: 100%|██████████| 189/189 [21:43<00:00,  6.90s/it]\n"
     ]
    }
   ],
   "source": [
    "pids = [f for f in os.listdir(base_url) if len(f) == 3]\n",
    "for pid in tqdm(pids, desc='Normalising landmarks feature'):\n",
    "    file_path = f'{base_url}{pid}/{pid}_CLNF_features.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    normalize_landmarks(df, glob_nt_x, glob_nt_y, glob_x_min, glob_x_max, glob_y_min, glob_y_max).to_csv(file_path, index=False) # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
